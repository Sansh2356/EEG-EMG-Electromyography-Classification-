{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS CUSTOM SCRIPT IS CREATED BY BOTH ME AND KARAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './Ninapro_DB1.csv'\n",
    "df = pd.read_csv(filename)\n",
    "df = df.sample(frac=1,random_state=42)\n",
    "df.to_csv('./shuffled_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# not required column names\n",
    "cols = [\"Unnamed: 0\", \"stimulus\", \"restimulus\",\n",
    "        \"repetition\", \"rerepetition\", \"subject\"]\n",
    "\n",
    "# Models\n",
    "KNN = KNeighborsClassifier(n_neighbors=5,\n",
    "                           weights=\"distance\",\n",
    "                           algorithm=\"auto\",\n",
    "                           leaf_size=50)\n",
    "\n",
    "# SVM = SVC(kernel=\"linear\", C=1)\n",
    "\n",
    "# RNDF = RandomForestClassifier(n_estimators=100,\n",
    "#                               criterion=\"log_loss\")\n",
    "\n",
    "# Variables\n",
    "_X = pd.DataFrame()\n",
    "_y = pd.Series()\n",
    "_X_train = pd.DataFrame()\n",
    "_y_train = pd.Series()\n",
    "_X_test = pd.DataFrame()\n",
    "_y_test = pd.Series()\n",
    "\n",
    "\n",
    "# start script\n",
    "def _start_(model_name, shuffled_data, chunk_size,  concat: bool = False):\n",
    "    \n",
    "    global _X, _y, _X_train, _y_train, _X_test, _y_test\n",
    "\n",
    "    print(f\"\\n[+] Training {model_name}\")\n",
    "\n",
    "    # helper function\n",
    "    def _concat_(_A, a):\n",
    "        if _A is None:\n",
    "            _A = a\n",
    "        else:\n",
    "            _A = pd.concat([_A, a], ignore_index=True)\n",
    "        return _A\n",
    "\n",
    "    # creating the chunk reader\n",
    "    csv_chunk_reader = pd.read_csv(filepath_or_buffer=shuffled_data,\n",
    "                                   chunksize=int(chunk_size),\n",
    "                                   na_filter=False)\n",
    "\n",
    "    # reading chunk-by-chunk\n",
    "    for chunk in csv_chunk_reader:\n",
    "        print(\"\\n[*] Running on new chunk\")\n",
    "        # dropping the columns\n",
    "        chunk.drop(cols, axis=1, inplace=True)\n",
    "\n",
    "        # features / labels\n",
    "        X = chunk.iloc[:, :-1]\n",
    "        y = chunk.iloc[:, -1]\n",
    "        print(\"features:\", X.shape)\n",
    "        print(\"label:\", y.shape)\n",
    "        print(y.value_counts(sort=True, ascending=True, dropna=False))\n",
    "\n",
    "        # checking for unique labels\n",
    "        unique_classes_chunk = unique_labels(y)\n",
    "\n",
    "        if len(unique_classes_chunk) < 2:\n",
    "            print(\"[-] Skipping chunk with only one class.\")\n",
    "            continue\n",
    "\n",
    "        # train-test splitting\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                            test_size=0.2,\n",
    "                                                            train_size=0.8,\n",
    "                                                            shuffle=True,\n",
    "                                                            random_state=98)\n",
    "        print(\"Splitted into train(80%) and test (20%)\")\n",
    "        print(\"X_train:\", X_train.shape)\n",
    "        print(\"y_train:\", y_train.shape)\n",
    "        print(\"X_test:\", X_test.shape)\n",
    "        print(\"y_test:\", y_test.shape)\n",
    "\n",
    "        # fitting into the model\n",
    "        model_name.fit(X_train, y_train)\n",
    "        print(f\"[+] Fitted model {model_name}\")\n",
    "\n",
    "        # concatenating the features and labels\n",
    "        if concat:\n",
    "            _X = _concat_(_X, X)\n",
    "            _y = _concat_(_y, y)\n",
    "            _X_train = _concat_(_X_train, X_train)\n",
    "            _y_train = _concat_(_y_train, _y_train)\n",
    "            _X_test = _concat_(_X_test, X_test)\n",
    "            _y_test = _concat_(_y_test, y_test)\n",
    "            print(\"[+] Concatenated Chunk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model(s) to the file(s)\n",
    "def save_model(_name, file_name: str = \"1.joblib\"):\n",
    "    joblib.dump(_name, filename=file_name)\n",
    "    print(f\"[+] {_name} saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[+] Training KNeighborsClassifier(leaf_size=50, weights='distance')\n",
      "\n",
      "[*] Running on new chunk\n",
      "features: (1000000, 33)\n",
      "label: (1000000,)\n",
      "exercise\n",
      "1    218095\n",
      "2    307731\n",
      "3    474174\n",
      "Name: count, dtype: int64\n",
      "Splitted into train(80%) and test (20%)\n",
      "X_train: (800000, 33)\n",
      "y_train: (800000,)\n",
      "X_test: (200000, 33)\n",
      "y_test: (200000,)\n",
      "[+] Fitted model KNeighborsClassifier(leaf_size=50, weights='distance')\n",
      "[+] Concatenated Chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91798\\AppData\\Local\\Temp\\ipykernel_18056\\129246627.py:36: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  _A = pd.concat([_A, a], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[*] Running on new chunk\n",
      "features: (1000000, 33)\n",
      "label: (1000000,)\n",
      "exercise\n",
      "1    217557\n",
      "2    308263\n",
      "3    474180\n",
      "Name: count, dtype: int64\n",
      "Splitted into train(80%) and test (20%)\n",
      "X_train: (800000, 33)\n",
      "y_train: (800000,)\n",
      "X_test: (200000, 33)\n",
      "y_test: (200000,)\n",
      "[+] Fitted model KNeighborsClassifier(leaf_size=50, weights='distance')\n",
      "[+] Concatenated Chunk\n",
      "\n",
      "[*] Running on new chunk\n",
      "features: (1000000, 33)\n",
      "label: (1000000,)\n",
      "exercise\n",
      "1    218387\n",
      "2    307967\n",
      "3    473646\n",
      "Name: count, dtype: int64\n",
      "Splitted into train(80%) and test (20%)\n",
      "X_train: (800000, 33)\n",
      "y_train: (800000,)\n",
      "X_test: (200000, 33)\n",
      "y_test: (200000,)\n",
      "[+] Fitted model KNeighborsClassifier(leaf_size=50, weights='distance')\n",
      "[+] Concatenated Chunk\n",
      "\n",
      "[*] Running on new chunk\n",
      "features: (1000000, 33)\n",
      "label: (1000000,)\n",
      "exercise\n",
      "1    217321\n",
      "2    308606\n",
      "3    474073\n",
      "Name: count, dtype: int64\n",
      "Splitted into train(80%) and test (20%)\n",
      "X_train: (800000, 33)\n",
      "y_train: (800000,)\n",
      "X_test: (200000, 33)\n",
      "y_test: (200000,)\n",
      "[+] Fitted model KNeighborsClassifier(leaf_size=50, weights='distance')\n",
      "[+] Concatenated Chunk\n",
      "\n",
      "[*] Running on new chunk\n",
      "features: (1000000, 33)\n",
      "label: (1000000,)\n",
      "exercise\n",
      "1    217125\n",
      "2    308300\n",
      "3    474575\n",
      "Name: count, dtype: int64\n",
      "Splitted into train(80%) and test (20%)\n",
      "X_train: (800000, 33)\n",
      "y_train: (800000,)\n",
      "X_test: (200000, 33)\n",
      "y_test: (200000,)\n",
      "[+] Fitted model KNeighborsClassifier(leaf_size=50, weights='distance')\n",
      "[+] Concatenated Chunk\n",
      "\n",
      "[*] Running on new chunk\n",
      "features: (1000000, 33)\n",
      "label: (1000000,)\n",
      "exercise\n",
      "1    217973\n",
      "2    308037\n",
      "3    473990\n",
      "Name: count, dtype: int64\n",
      "Splitted into train(80%) and test (20%)\n",
      "X_train: (800000, 33)\n",
      "y_train: (800000,)\n",
      "X_test: (200000, 33)\n",
      "y_test: (200000,)\n",
      "[+] Fitted model KNeighborsClassifier(leaf_size=50, weights='distance')\n",
      "[+] Concatenated Chunk\n",
      "\n",
      "[*] Running on new chunk\n",
      "features: (1000000, 33)\n",
      "label: (1000000,)\n",
      "exercise\n",
      "1    217340\n",
      "2    308184\n",
      "3    474476\n",
      "Name: count, dtype: int64\n",
      "Splitted into train(80%) and test (20%)\n",
      "X_train: (800000, 33)\n",
      "y_train: (800000,)\n",
      "X_test: (200000, 33)\n",
      "y_test: (200000,)\n",
      "[+] Fitted model KNeighborsClassifier(leaf_size=50, weights='distance')\n",
      "[+] Concatenated Chunk\n",
      "\n",
      "[*] Running on new chunk\n",
      "features: (1000000, 33)\n",
      "label: (1000000,)\n",
      "exercise\n",
      "1    216820\n",
      "2    308333\n",
      "3    474847\n",
      "Name: count, dtype: int64\n",
      "Splitted into train(80%) and test (20%)\n",
      "X_train: (800000, 33)\n",
      "y_train: (800000,)\n",
      "X_test: (200000, 33)\n",
      "y_test: (200000,)\n",
      "[+] Fitted model KNeighborsClassifier(leaf_size=50, weights='distance')\n",
      "[+] Concatenated Chunk\n",
      "\n",
      "[*] Running on new chunk\n",
      "features: (1000000, 33)\n",
      "label: (1000000,)\n",
      "exercise\n",
      "1    217263\n",
      "2    308386\n",
      "3    474351\n",
      "Name: count, dtype: int64\n",
      "Splitted into train(80%) and test (20%)\n",
      "X_train: (800000, 33)\n",
      "y_train: (800000,)\n",
      "X_test: (200000, 33)\n",
      "y_test: (200000,)\n",
      "[+] Fitted model KNeighborsClassifier(leaf_size=50, weights='distance')\n",
      "[+] Concatenated Chunk\n",
      "\n",
      "[*] Running on new chunk\n",
      "features: (1000000, 33)\n",
      "label: (1000000,)\n",
      "exercise\n",
      "1    217907\n",
      "2    307878\n",
      "3    474215\n",
      "Name: count, dtype: int64\n",
      "Splitted into train(80%) and test (20%)\n",
      "X_train: (800000, 33)\n",
      "y_train: (800000,)\n",
      "X_test: (200000, 33)\n",
      "y_test: (200000,)\n",
      "[+] Fitted model KNeighborsClassifier(leaf_size=50, weights='distance')\n",
      "[+] Concatenated Chunk\n",
      "\n",
      "[*] Running on new chunk\n",
      "features: (1000000, 33)\n",
      "label: (1000000,)\n",
      "exercise\n",
      "1    216899\n",
      "2    308539\n",
      "3    474562\n",
      "Name: count, dtype: int64\n",
      "Splitted into train(80%) and test (20%)\n",
      "X_train: (800000, 33)\n",
      "y_train: (800000,)\n",
      "X_test: (200000, 33)\n",
      "y_test: (200000,)\n",
      "[+] Fitted model KNeighborsClassifier(leaf_size=50, weights='distance')\n",
      "[+] Concatenated Chunk\n",
      "\n",
      "[*] Running on new chunk\n",
      "features: (1000000, 33)\n",
      "label: (1000000,)\n",
      "exercise\n",
      "1    218498\n",
      "2    307795\n",
      "3    473707\n",
      "Name: count, dtype: int64\n",
      "Splitted into train(80%) and test (20%)\n",
      "X_train: (800000, 33)\n",
      "y_train: (800000,)\n",
      "X_test: (200000, 33)\n",
      "y_test: (200000,)\n",
      "[+] Fitted model KNeighborsClassifier(leaf_size=50, weights='distance')\n",
      "[+] Concatenated Chunk\n",
      "\n",
      "[*] Running on new chunk\n",
      "features: (553611, 33)\n",
      "label: (553611,)\n",
      "exercise\n",
      "1    120208\n",
      "2    170549\n",
      "3    262854\n",
      "Name: count, dtype: int64\n",
      "Splitted into train(80%) and test (20%)\n",
      "X_train: (442888, 33)\n",
      "y_train: (442888,)\n",
      "X_test: (110723, 33)\n",
      "y_test: (110723,)\n",
      "[+] Fitted model KNeighborsClassifier(leaf_size=50, weights='distance')\n",
      "[+] Concatenated Chunk\n",
      "\n",
      "[+] KNN trained successfully\n",
      "[+] KNeighborsClassifier(leaf_size=50, weights='distance') saved to knn_model.joblib\n"
     ]
    }
   ],
   "source": [
    "# starting the training process\n",
    "CHUNK_SIZE = 1e6\n",
    "\n",
    "_start_(model_name=KNN,\n",
    "        shuffled_data='./shuffled_data.csv',\n",
    "        chunk_size=CHUNK_SIZE,  concat=True)\n",
    "print(\"\\n[+] KNN trained successfully\")\n",
    "save_model(KNN, \"knn_model.joblib\")\n",
    "\n",
    "# _start_(model_name=RNDF,\n",
    "#         shuffled_data=shuffled_data_filepath,\n",
    "#         chunk_size=CHUNK_SIZE)\n",
    "# print(\"\\n[+] Random Forest trained successfully\")\n",
    "# save_model(RNDF, \"rndf_model.joblib\")\n",
    "\n",
    "# _start_(model_name=SVM,\n",
    "#         shuffled_data=shuffled_data_filepath,\n",
    "#         chunk_size=CHUNK_SIZE)\n",
    "# print(\"\\n[+] SVM trained successfully\")\n",
    "# save_model(SVM, \"svm_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: (12553611, 33)\n",
      "labels: (12553611,)\n",
      "features: (10042888, 33)\n",
      "labels: (0,)\n",
      "test features: (2510723, 33)\n",
      "test labels: (2510723,)\n"
     ]
    }
   ],
   "source": [
    "# saving the variables\n",
    "joblib.dump(_X, \"feature.joblib\")\n",
    "joblib.dump(_y, \"labels.joblib\")\n",
    "joblib.dump(_X_train, \"train_features.joblib\")\n",
    "joblib.dump(_y_train, \"train_labels.joblib\")\n",
    "joblib.dump(_X_test, \"test_features.joblib\")\n",
    "joblib.dump(_y_test, \"test_labels.joblib\")\n",
    "\n",
    "# info\n",
    "print(\"features:\", _X.shape)\n",
    "print(\"labels:\", _y.shape)\n",
    "print(\"features:\", _X_train.shape)\n",
    "print(\"labels:\", _y_train.shape)\n",
    "print(\"test features:\", _X_test.shape)\n",
    "print(\"test labels:\", _y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN predictions: [2 3 1 ... 3 1 2]\n"
     ]
    }
   ],
   "source": [
    "knn_predicts = KNN.predict(_X_test)\n",
    "print(\"KNN predictions:\", knn_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracies\n",
    "def calc_accuracy(classifier, X, y):\n",
    "    accuracies = cross_val_score(estimator=classifier, X=X, y=y, cv=10)\n",
    "    print(accuracies.mean())\n",
    "    print(accuracies.std())\n",
    "\n",
    "# confusion matrix\n",
    "def show_matrix(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 890, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1351, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 238, in fit\n    return self._fit(X, y)\n           ^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 476, in _fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1192, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 951, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 521, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2083, in __array__\n    values = self._values\n             ^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py\", line 1046, in _values\n    return ensure_wrapped_if_datetimelike(self.values)\n                                          ^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py\", line 12281, in values\n    return self._mgr.as_array()\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1656, in as_array\n    arr = self._interleave(dtype=dtype, na_value=na_value)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1689, in _interleave\n    result = np.empty(self.shape, dtype=dtype)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.78 GiB for an array with shape (33, 11298249) and data type float64\n\n--------------------------------------------------------------------------------\n9 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 890, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1351, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 238, in fit\n    return self._fit(X, y)\n           ^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 476, in _fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1192, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 951, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 521, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2083, in __array__\n    values = self._values\n             ^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py\", line 1046, in _values\n    return ensure_wrapped_if_datetimelike(self.values)\n                                          ^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py\", line 12281, in values\n    return self._mgr.as_array()\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1656, in as_array\n    arr = self._interleave(dtype=dtype, na_value=na_value)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1689, in _interleave\n    result = np.empty(self.shape, dtype=dtype)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.78 GiB for an array with shape (33, 11298250) and data type float64\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m calc_accuracy(KNN, _X, _y)\n",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m, in \u001b[0;36mcalc_accuracy\u001b[1;34m(classifier, X, y)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalc_accuracy\u001b[39m(classifier, X, y):\n\u001b[1;32m----> 3\u001b[0m     accuracies \u001b[39m=\u001b[39m cross_val_score(estimator\u001b[39m=\u001b[39;49mclassifier, X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, cv\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(accuracies\u001b[39m.\u001b[39mmean())\n\u001b[0;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(accuracies\u001b[39m.\u001b[39mstd())\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:714\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    711\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    712\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 714\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    715\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    716\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    717\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    718\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    719\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    720\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    721\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    722\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    723\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    724\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    725\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    726\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    727\u001b[0m )\n\u001b[0;32m    728\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:445\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    424\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m    425\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    426\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    427\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m indices\n\u001b[0;32m    443\u001b[0m )\n\u001b[1;32m--> 445\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    447\u001b[0m \u001b[39m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:531\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[0;32m    525\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    526\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    529\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    530\u001b[0m     )\n\u001b[1;32m--> 531\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    533\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    534\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    535\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    536\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    541\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 890, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1351, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 238, in fit\n    return self._fit(X, y)\n           ^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 476, in _fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1192, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 951, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 521, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2083, in __array__\n    values = self._values\n             ^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py\", line 1046, in _values\n    return ensure_wrapped_if_datetimelike(self.values)\n                                          ^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py\", line 12281, in values\n    return self._mgr.as_array()\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1656, in as_array\n    arr = self._interleave(dtype=dtype, na_value=na_value)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1689, in _interleave\n    result = np.empty(self.shape, dtype=dtype)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.78 GiB for an array with shape (33, 11298249) and data type float64\n\n--------------------------------------------------------------------------------\n9 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 890, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1351, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 238, in fit\n    return self._fit(X, y)\n           ^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 476, in _fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1192, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 951, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 521, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2083, in __array__\n    values = self._values\n             ^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py\", line 1046, in _values\n    return ensure_wrapped_if_datetimelike(self.values)\n                                          ^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py\", line 12281, in values\n    return self._mgr.as_array()\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1656, in as_array\n    arr = self._interleave(dtype=dtype, na_value=na_value)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1689, in _interleave\n    result = np.empty(self.shape, dtype=dtype)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.78 GiB for an array with shape (33, 11298250) and data type float64\n"
     ]
    }
   ],
   "source": [
    "calc_accuracy(KNN, _X, _y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999641537517281\n"
     ]
    }
   ],
   "source": [
    "ac = accuracy_score(_y_test,knn_predicts)\n",
    "print(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 546762      28       0]\n",
      " [     14  772560       0]\n",
      " [     32      16 1191311]]\n"
     ]
    }
   ],
   "source": [
    "show_matrix(_y_test, knn_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2 (tags/v3.11.2:878ead1, Feb  7 2023, 16:38:35) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
